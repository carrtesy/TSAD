{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SWaT Anomaly Detection with OmniAnomaly\n",
    "\n",
    "by dongmin kim (tommy.dm.kim@gmail.com)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "HOME = \"../../../\"\n",
    "sys.path.append(HOME) # repo home"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from exp_helpers.utils import SEED_everything\n",
    "SEED_everything(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    # general\n",
    "    \"dataset\": \"SWaT\",\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 1e-03,\n",
    "    \"window_size\": 100,\n",
    "    \"epochs\": 30,\n",
    "    \"use_tqdm\": True,\n",
    "    \"tqdmopt\": \"notebook\",\n",
    "    \"load_pretrained\": False,\n",
    "\n",
    "    # model-specific (OmniAnomaly)\n",
    "    \"model\": \"OmniAnomaly\",\n",
    "    \"latent_dim\": 128,\n",
    "    \"num_layers\": 1,\n",
    "    \"z_dim\": 3,\n",
    "    \"dense_dim\": 10,\n",
    "\n",
    "    # others\n",
    "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'),\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "config = \"\"\n",
    "config += f\"_dataset_{args.dataset}\" \\\n",
    "          f\"_batch_size_{args.batch_size}\" \\\n",
    "          f\"_lr_{args.lr}\" \\\n",
    "          f\"_window_size_{args.window_size}\" \\\n",
    "\n",
    "config += f\"_model_{args.model}\" \\\n",
    "          f\"_latent_dim_{args.latent_dim}\" \\\n",
    "          f\"_num_layers_{args.num_layers}\" \\\n",
    "          f\"_z_dim_{args.z_dim}\" \\\n",
    "          f\"_dense_dim_{args.dense_dim}\"\n",
    "\n",
    "args.config = config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../models/checkpoints/_dataset_SWaT_batch_size_64_lr_0.001_window_size_100_model_OmniAnomaly_latent_dim_128_num_layers_1_z_dim_3_dense_dim_10/model.pt\n",
      "../../../results/OmniAnomaly/_dataset_SWaT_batch_size_64_lr_0.001_window_size_100_model_OmniAnomaly_latent_dim_128_num_layers_1_z_dim_3_dense_dim_10\n"
     ]
    }
   ],
   "source": [
    "# PATH to save model\n",
    "os.makedirs(os.path.join(HOME, \"models\", \"checkpoints\", f\"{args.config}\"), exist_ok=True)\n",
    "args.model_path = os.path.join(HOME, \"models\", \"checkpoints\", f\"{args.config}\", \"model.pt\")\n",
    "\n",
    "# PATH to save result figures\n",
    "os.makedirs(os.path.join(HOME, \"results\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(HOME, \"results\", args.model), exist_ok=True)\n",
    "os.makedirs(os.path.join(HOME, \"results\", args.model, args.config), exist_ok=True)\n",
    "args.result_path = os.path.join(HOME, \"results\", args.model, args.config)\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(args.model_path)\n",
    "print(args.result_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SWaT...\n",
      "current location: /home/nas3_userJ/dmkim/TSAD/notebooks/Modeling/SWaT\n",
      "home dir: ../../../\n",
      "Loading complete.\n"
     ]
    }
   ],
   "source": [
    "from data.load_data import load_data\n",
    "from data.dataset import get_dataset\n",
    "\n",
    "train_x, train_y, test_x, test_y = load_data(args.dataset, HOME)\n",
    "\n",
    "train_dataset = get_dataset(train_x, train_y, window_size = args.window_size, dataset_type=args.dataset)\n",
    "test_dataset = get_dataset(test_x, test_y, window_size = args.window_size, dataset_type=args.dataset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_dataset,\n",
    "                 batch_size=args.batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_dataset,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "args.input_dim = train_x.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting model to cuda...\n"
     ]
    },
    {
     "data": {
      "text/plain": "OmniAnomaly(\n  (qnet): Qnet(\n    (gru): GRU(51, 128, batch_first=True)\n    (dense): Linear(in_features=131, out_features=10, bias=True)\n    (linear_mu): Linear(in_features=10, out_features=3, bias=True)\n    (linear_sigma): Linear(in_features=10, out_features=3, bias=True)\n    (softplus): Softplus(beta=1, threshold=20)\n    (pnf): PlanarNormalizingFlow(\n      (linear): Linear(in_features=3, out_features=3, bias=True)\n      (tanh): Tanh()\n    )\n  )\n  (pnet): Pnet(\n    (gru): GRU(3, 128, batch_first=True)\n    (LGSSM): Linear(in_features=3, out_features=3, bias=True)\n    (dense): Linear(in_features=128, out_features=10, bias=True)\n    (linear_mu): Linear(in_features=10, out_features=51, bias=True)\n    (linear_sigma): Linear(in_features=10, out_features=51, bias=True)\n    (softplus): Softplus(beta=1, threshold=20)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.utils import prepare_model, prepare_loss_fn\n",
    "print(f\"setting model to {args.device}...\")\n",
    "model = prepare_model(args)\n",
    "model.to(args.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "{'dataset': 'SWaT', 'batch_size': 64, 'lr': 0.001, 'window_size': 100, 'epochs': 30, 'use_tqdm': True, 'tqdmopt': 'notebook', 'load_pretrained': False, 'model': 'OmniAnomaly', 'latent_dim': 128, 'num_layers': 1, 'z_dim': 3, 'dense_dim': 10, 'device': device(type='cuda'), 'config': '_dataset_SWaT_batch_size_64_lr_0.001_window_size_100_model_OmniAnomaly_latent_dim_128_num_layers_1_z_dim_3_dense_dim_10', 'model_path': '../../../models/checkpoints/_dataset_SWaT_batch_size_64_lr_0.001_window_size_100_model_OmniAnomaly_latent_dim_128_num_layers_1_z_dim_3_dense_dim_10/model.pt', 'result_path': '../../../results/OmniAnomaly/_dataset_SWaT_batch_size_64_lr_0.001_window_size_100_model_OmniAnomaly_latent_dim_128_num_layers_1_z_dim_3_dense_dim_10', 'input_dim': 51}\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/30 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8e974e7998c47778ccad56ae8febbec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training:   0%|          | 0/7761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fd9e8ff2ef647bbbcb754c79d7fd3d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training:   0%|          | 0/7761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24a3c2e0c45547f78750ee75a2e2dcdb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "training:   0%|          | 0/7761 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b0264afd08e42b3af4f9ea973a898ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from exp_helpers.exp_OmniAnomaly import OmniAnomaly_Trainer\n",
    "\n",
    "if args.load_pretrained is True:\n",
    "    print(f\"loading pretrained model at {args.model_path}...\")\n",
    "    best_model = model\n",
    "    best_model.load_state_dict(torch.load(args.model_path))\n",
    "    best_model.to(args.device)\n",
    "    print(\"done\")\n",
    "else:\n",
    "    print(\"start training...\")\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr = args.lr)\n",
    "    loss_fn = prepare_loss_fn(args)\n",
    "\n",
    "    trainer = OmniAnomaly_Trainer(\n",
    "        args=args,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "    )\n",
    "\n",
    "    best_model = trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from exp_helpers.exp_OmniAnomaly import OmniAnomaly_Tester\n",
    "\n",
    "tester = OmniAnomaly_Tester(\n",
    "    args = args,\n",
    "    model = best_model,\n",
    "    train_loader = train_loader,\n",
    "    test_loader = test_loader,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.load_data import load_anomaly_intervals"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomaly_scores = tester.get_anomaly_score()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "intervals = load_anomaly_intervals(anomaly_labels = test_y, window_size = args.window_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_threshold = tester.regular_thresholding(test_y, anomaly_scores, intervals, num_candidates = 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}