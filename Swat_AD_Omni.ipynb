{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_data(is_train=True):\n",
    "    if is_train:\n",
    "        sensor_path = './dataset/SWaT/SWaT_Dataset_Normal_v0.csv'\n",
    "        df = pd.read_csv(sensor_path, index_col=0)\n",
    "    else:\n",
    "        sensor_path = './dataset/SWaT/SWaT_Dataset_Attack_v0.csv'\n",
    "        df = pd.read_csv(sensor_path, index_col=0)\n",
    "\n",
    "    for var_index in [item for item in df.columns if item != 'Normal/Attack']:\n",
    "        df[var_index] = pd.to_numeric(df[var_index], errors='coerce')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    print(df.head())\n",
    "    x = df.values[:,:-1].astype(np.float32)\n",
    "    y = (df['Normal/Attack']=='Attack').to_numpy().astype(int)\n",
    "\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FIT101    LIT101  MV101  P101  P102    AIT201   AIT202   AIT203  \\\n",
      "0  2.470294  261.5804      2     2     1  244.3284  8.19008  306.101   \n",
      "1  2.457163  261.1879      2     2     1  244.3284  8.19008  306.101   \n",
      "2  2.439548  260.9131      2     2     1  244.3284  8.19008  306.101   \n",
      "3  2.428338  260.2850      2     2     1  244.3284  8.19008  306.101   \n",
      "4  2.424815  259.8925      2     2     1  244.4245  8.19008  306.101   \n",
      "\n",
      "     FIT201  MV201  ...  P501  P502    PIT501  PIT502    PIT503    FIT601  \\\n",
      "0  2.471278      2  ...     1     1  10.02948     0.0  4.277749  0.000256   \n",
      "1  2.468587      2  ...     1     1  10.02948     0.0  4.277749  0.000256   \n",
      "2  2.467305      2  ...     1     1  10.02948     0.0  4.277749  0.000256   \n",
      "3  2.466536      2  ...     1     1  10.02948     0.0  4.277749  0.000256   \n",
      "4  2.466536      2  ...     1     1  10.02948     0.0  4.277749  0.000256   \n",
      "\n",
      "   P601  P602  P603  Normal/Attack  \n",
      "0     1     1     1         Normal  \n",
      "1     1     1     1         Normal  \n",
      "2     1     1     1         Normal  \n",
      "3     1     1     1         Normal  \n",
      "4     1     1     1         Normal  \n",
      "\n",
      "[5 rows x 52 columns]\n",
      "     FIT101    LIT101   MV101  P101  P102    AIT201    AIT202    AIT203  \\\n",
      "0  2.427057  522.8467       2     2     1  262.0161  8.396437  328.6337   \n",
      "1  2.446274  522.8860       2     2     1  262.0161  8.396437  328.6337   \n",
      "2  2.489191  522.8467       2     2     1  262.0161  8.394514  328.6337   \n",
      "3  2.534350  522.9645       2     2     1  262.0161  8.394514  328.6337   \n",
      "4  2.569260  523.4748       2     2     1  262.0161  8.394514  328.6337   \n",
      "\n",
      "     FIT201   MV201  ...  P501  P502    PIT501    PIT502    PIT503    FIT601  \\\n",
      "0  2.445391       2  ...     2     1  250.8652  1.649953  189.5988  0.000128   \n",
      "1  2.445391       2  ...     2     1  250.8652  1.649953  189.6789  0.000128   \n",
      "2  2.442316       2  ...     2     1  250.8812  1.649953  189.6789  0.000128   \n",
      "3  2.442316       2  ...     2     1  250.8812  1.649953  189.6148  0.000128   \n",
      "4  2.443085       2  ...     2     1  250.8812  1.649953  189.5027  0.000128   \n",
      "\n",
      "   P601  P602  P603  Normal/Attack  \n",
      "0     1     1     1         Normal  \n",
      "1     1     1     1         Normal  \n",
      "2     1     1     1         Normal  \n",
      "3     1     1     1         Normal  \n",
      "4     1     1     1         Normal  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(True)\n",
    "test_x, test_y = load_data(False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_min = np.min(train_x, 0, keepdims=True)\n",
    "x_max = np.max(train_x, 0, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"batch_size\": 128, ## 배치 사이즈 설정\n",
    "    \"device\": torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'), ## GPU 사용 여부 설정\n",
    "    \"input_size\": train_x.shape[1], ## 입력 차원 설정\n",
    "    \"latent_size\": 10, ## Hidden 차원 설정\n",
    "    \"output_size\": train_x.shape[1], ## 출력 차원 설정\n",
    "    \"window_size\" : 3, ## sequence Lenght\n",
    "    \"num_layers\": 2,     ## LSTM layer 갯수 설정\n",
    "    \"learning_rate\" : 0.001, ## learning rate 설정\n",
    "    \"max_iter\" : 100000, ## 총 반복 횟수 설정\n",
    "    'early_stop' : True,  ## valid loss가 작아지지 않으면 early stop 조건 설정\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class SWaTDataset(Dataset):\n",
    "    def __init__(self, x, y, x_min, x_max, window_size=1):\n",
    "        super().__init__()\n",
    "        t = (x_min != x_max).astype(np.float32)\n",
    "        self.x = (x - x_min) / (x_max-x_min + 1e-5) * t\n",
    "        self.y = y\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0] - self.window_size + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx:idx+self.window_size], self.y[idx:idx+self.window_size]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_dataset = SWaTDataset(train_x, train_y, x_min, x_max, window_size=args.window_size)\n",
    "test_dataset = SWaTDataset(test_x, test_y, x_min, x_max, window_size=args.window_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                 dataset=train_dataset,\n",
    "                 batch_size=args.batch_size,\n",
    "                 shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                dataset=test_dataset,\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Omnianomaly_pytorch.model import OmniAnomaly\n",
    "\n",
    "model = OmniAnomaly(\n",
    "    in_dim=args.input_size,\n",
    "    hidden_dim=10,\n",
    "    z_dim=3,\n",
    "    dense_dim=10,\n",
    "    out_dim=args.input_size\n",
    ")\n",
    "\n",
    "model.to(args.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loss_function(x, pred_x, mu, logvar):\n",
    "    MSE_loss = F.mse_loss(x, pred_x)\n",
    "    KLD_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE_loss + KLD_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Training\n",
    "best_loss = None\n",
    "epochs = tqdm(range(args.max_iter//len(train_loader)+1), leave=True)\n",
    "for epoch in epochs:\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_iterator = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"training\", leave=True)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for i, batch_data in train_iterator:\n",
    "        batch_data = batch_data[0].to(args.device)\n",
    "        predict_values, mu, logvar = model(batch_data)\n",
    "\n",
    "        # Backward and optimize\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(batch_data, predict_values, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_iterator.set_postfix({\n",
    "            \"train_loss\": float(loss),\n",
    "        })\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    epochs.set_postfix({\n",
    "         \"Train Loss\": train_loss,\n",
    "    })\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\", leave=True)\n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in test_iterator:\n",
    "\n",
    "            batch_data = batch_data[0].to(args.device)\n",
    "            predict_values, mu, logvar = model(batch_data)\n",
    "            loss = loss_function(batch_data, predict_values, mu, logvar)\n",
    "\n",
    "            eval_loss += loss.mean().item()\n",
    "\n",
    "            test_iterator.set_postfix({\n",
    "                \"eval_loss\": float(loss),\n",
    "            })\n",
    "\n",
    "    eval_loss = eval_loss / len(test_loader)\n",
    "    epochs.set_postfix({\n",
    "         \"Evaluation Score\": float(eval_loss),\n",
    "    })\n",
    "    if best_loss is None or eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "    else:\n",
    "        if args.early_stop:\n",
    "            print('early stop condition   best_loss[{}]  eval_loss[{}]'.format(best_loss, eval_loss))\n",
    "            break\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_loss_list(args, model, test_loader):\n",
    "    test_iterator = tqdm(enumerate(test_loader), total=len(test_loader), desc=\"testing\")\n",
    "    loss_list = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch_data in test_iterator:\n",
    "            batch_data = batch_data[0].to(args.device)\n",
    "            predict_values, _, _ = model(batch_data)\n",
    "\n",
    "            loss = F.mse_loss(batch_data, predict_values, reduce=False)\n",
    "            loss = loss.mean(dim=1).cpu().numpy()\n",
    "            loss_list.append(loss)\n",
    "\n",
    "    loss_list = np.concatenate(loss_list, axis=0)\n",
    "    return loss_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss_list = get_loss_list(args, model, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss_list.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomaly_scores = np.mean(test_loss_list, axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(anomaly_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = list(range(len(anomaly_scores)))\n",
    "y = anomaly_scores\n",
    "\n",
    "window_y = []\n",
    "for i in x:\n",
    "    window_y.append(min(test_y[i:i+args.window_size])==0)\n",
    "\n",
    "intervals = []\n",
    "start = None\n",
    "for i, label in enumerate(window_y):\n",
    "    if label:\n",
    "        if start is None:\n",
    "            start = i\n",
    "    else:\n",
    "        if start is not None:\n",
    "            intervals.append((start, i-1))\n",
    "        start = None\n",
    "if start is not None:\n",
    "    intervals.append((start, len(window_y)-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(intervals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## 시각화 하기\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax=fig.add_subplot()\n",
    "\n",
    "ax.plot(x, y)\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "for s, e in intervals:\n",
    "    ax.axvspan(s, e, alpha=0.2, color='orange')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding Threshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(anomaly_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min, max = np.min(anomaly_scores), np.max(anomaly_scores)\n",
    "min, max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomaly_scores.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresholds = np.linspace(min, max, 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(thresholds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    anomaly_prediction = (anomaly_scores > threshold).astype(int)\n",
    "    target_y = test_y[args.window_size-1:]\n",
    "\n",
    "    precisions.append(precision_score(target_y, anomaly_prediction, zero_division = 1))\n",
    "    recalls.append(recall_score(target_y, anomaly_prediction, zero_division = 1))\n",
    "    f1s.append(f1_score(target_y, anomaly_prediction, zero_division = 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(thresholds, precisions, label = \"precision\")\n",
    "plt.plot(thresholds, recalls, label = \"recall\")\n",
    "plt.plot(thresholds, f1s, label = \"f1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "threshold_idx = np.argmax(f1s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_threshold = thresholds[threshold_idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "ax=fig.add_subplot()\n",
    "ax.axhline(y = best_threshold, color = \"r\")\n",
    "ax.plot(x, y)\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "for s, e in intervals:\n",
    "    ax.axvspan(s, e, alpha=0.2, color='orange')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "anomaly_prediction = (anomaly_scores > best_threshold).astype(int)\n",
    "target_y = test_y[args.window_size-1:]\n",
    "\n",
    "p, r, f = precision_score(target_y, anomaly_prediction), recall_score(target_y, anomaly_prediction),f1_score(target_y, anomaly_prediction)\n",
    "p, r, f"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(confusion_matrix(target_y, anomaly_prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(target_y, anomaly_prediction), annot = True, fmt = \"d\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}